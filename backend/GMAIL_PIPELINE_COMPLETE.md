# ğŸ“§ Complete Gmail Resume Processing Pipeline

## ğŸ”„ Full Pipeline Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     GMAIL RESUME PIPELINE                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. TRIGGER (3 Ways)
   â”œâ”€ A) Automatic Cron Job (Every 15 min) â†’ tasks/scheduler.py
   â”œâ”€ B) Manual API Call â†’ POST /api/v1/integrations/gmail/process-resumes
   â””â”€ C) Frontend Button Click â†’ Uses API endpoint

                        â†“

2. GMAIL INTEGRATION (modules/integrations/gmail.py)
   â”œâ”€ Connect to Gmail via Composio
   â”œâ”€ Fetch emails with attachments (last 7 days)
   â”œâ”€ Filter: PDF, DOCX, TXT files only
   â”œâ”€ Download attachments â†’ ./data/resumes/
   â””â”€ Return list of emails with file paths

                        â†“

3. RESUME PROCESSING (modules/resume/gmail_monitor.py)
   â”œâ”€ For each email attachment:
   â”‚  â”œâ”€ EXTRACTION (extractor.py)
   â”‚  â”‚  â”œâ”€ Read PDF/DOCX/TXT file
   â”‚  â”‚  â”œâ”€ Extract text with PyPDF2/python-docx
   â”‚  â”‚  â”œâ”€ Parse: name, email, phone, skills, experience, education
   â”‚  â”‚  â””â”€ Output: extracted_data dict
   â”‚  â”‚
   â”‚  â”œâ”€ ENRICHMENT (enricher.py)
   â”‚  â”‚  â”œâ”€ Send skills to Google Gemini API
   â”‚  â”‚  â”œâ”€ AI infers additional skills from experience
   â”‚  â”‚  â”œâ”€ Categorize skills (Technical, Soft, Domain)
   â”‚  â”‚  â””â”€ Output: enriched_data dict
   â”‚  â”‚
   â”‚  â””â”€ FORMATTING (formatter.py)
   â”‚     â”œâ”€ Combine extracted + enriched data
   â”‚     â”œâ”€ Structure in standard format
   â”‚     â”œâ”€ Add metadata (timestamp, source)
   â”‚     â””â”€ Output: final candidate JSON
   â”‚
   â””â”€ Save to ./data/candidates/{email}.json

                        â†“

4. STORAGE & NOTIFICATION
   â”œâ”€ Save resume file â†’ ./data/users/{user_id}/resumes/
   â”œâ”€ Save candidate JSON â†’ ./data/users/{user_id}/candidates/
   â”œâ”€ Log processing results
   â””â”€ (Future) Notify scoring pipeline

                        â†“

5. READY FOR SCORING (Person 5's work)
   â””â”€ Candidate JSON ready to be scored against job descriptions
```

---

## ğŸ“ File Structure

```
backend/
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ integrations/
â”‚   â”‚   â””â”€â”€ gmail.py              âœ… Person 4: Gmail API integration
â”‚   â””â”€â”€ resume/
â”‚       â”œâ”€â”€ gmail_monitor.py      âœ… Person 2: Orchestrates pipeline
â”‚       â”œâ”€â”€ extractor.py          âœ… Person 2: Extract resume data
â”‚       â”œâ”€â”€ enricher.py           âœ… Person 2: AI enrichment with Gemini
â”‚       â””â”€â”€ formatter.py          âœ… Person 2: Format final JSON
â”‚
â”œâ”€â”€ api/
â”‚   â””â”€â”€ integrations.py           âœ… REST API endpoints
â”‚
â”œâ”€â”€ tasks/
â”‚   â””â”€â”€ scheduler.py              âœ… Cron job (every 15 min)
â”‚
â””â”€â”€ data/users/{user_id}/
    â”œâ”€â”€ resumes/                  âœ… Downloaded PDF/DOCX files
    â””â”€â”€ candidates/               âœ… Processed JSON files
```

---

## ğŸ”§ Components Breakdown

### 1. **Gmail Integration** (`modules/integrations/gmail.py`)

**Owner:** Person 4  
**Status:** âœ… IMPLEMENTED

**Key Method:** `check_for_new_resumes(user_id, use_mock=False)`

```python
# What it does:
1. Connects to Gmail via Composio SDK
2. Fetches emails: "has:attachment newer_than:7d"
3. Filters attachments: .pdf, .docx, .txt only
4. Downloads files using GMAIL_GET_ATTACHMENT action
5. Moves files from ~/.composio/outputs/ to ./data/resumes/
6. Returns list of email objects with file paths

# Returns:
[
  {
    'subject': 'Application for Software Engineer',
    'from': 'candidate@email.com',
    'message_id': 'msg_123',
    'attachments': [{
      'file_path': './data/resumes/candidate_resume.pdf',
      'filename': 'candidate_resume.pdf',
      'mime_type': 'application/pdf'
    }]
  }
]
```

---

### 2. **Gmail Monitor** (`modules/resume/gmail_monitor.py`)

**Owner:** Person 2  
**Status:** âœ… IMPLEMENTED

**Key Method:** `process_new_emails(user_id, use_mock=False)`

```python
# Orchestrates the complete pipeline:
1. Call GmailIntegration.check_for_new_resumes()
2. For each email with attachment:
   a. Extract data (extractor.py)
   b. Enrich with AI (enricher.py)
   c. Format output (formatter.py)
   d. Save candidate JSON
3. Return list of processed candidates

# Returns:
[
  {
    'name': 'Ashish Kumar',
    'email': 'ashparmar08@gmail.com',
    'extracted_data': {...},
    'enriched_data': {...},
    'metadata': {...}
  }
]
```

---

### 3. **Resume Extractor** (`modules/resume/extractor.py`)

**Owner:** Person 2  
**Status:** âœ… IMPLEMENTED

```python
# Extraction Process:
1. Read file (PDF/DOCX/TXT)
   - PDF: Use PyPDF2
   - DOCX: Use python-docx
   - TXT: Direct read

2. Parse structured data:
   - Name (regex patterns)
   - Email (regex: \S+@\S+)
   - Phone (regex: various formats)
   - Skills (keyword matching + ML)
   - Experience (section detection)
   - Education (section detection)

3. Return extracted_data dict
```

---

### 4. **Resume Enricher** (`modules/resume/enricher.py`)

**Owner:** Person 2  
**Status:** âœ… IMPLEMENTED (AI Enrichment)

```python
# Enrichment with Google Gemini:
1. Take extracted skills list
2. Send to Gemini API with prompt:
   "Analyze these skills and infer additional relevant skills..."
3. AI returns:
   - Inferred skills (based on experience)
   - Skill categories (Technical, Soft, Domain)
   - Proficiency levels
4. Return enriched_data dict

# AI Prompt Example:
"Given these skills: Python, FastAPI, React
 Infer additional skills this person likely has:
 - Programming languages
 - Frameworks
 - Tools & technologies"

# AI Response:
{
  'ai_inferred_skills': ['JavaScript', 'REST API', 'Git', ...],
  'skill_categories': {...},
  'proficiency_levels': {...}
}
```

---

### 5. **Resume Formatter** (`modules/resume/formatter.py`)

**Owner:** Person 2  
**Status:** âœ… IMPLEMENTED

```python
# Formatting Process:
1. Merge extracted_data + enriched_data
2. Apply standard JSON structure
3. Add metadata:
   - Processing timestamp
   - Source (Gmail)
   - File path
4. Validate required fields
5. Return final candidate JSON

# Output Structure:
{
  "name": "Ashish Kumar",
  "email": "ashparmar08@gmail.com",
  "phone": "555-1234",
  "extracted_data": {
    "skills": ["Python", "FastAPI", ...],
    "experience": [...],
    "education": [...]
  },
  "enriched_data": {
    "ai_inferred_skills": ["REST API", "Git", ...],
    "skill_categories": {...}
  },
  "metadata": {
    "processed_at": "2025-11-18T10:30:00",
    "source": "gmail",
    "resume_file": "./data/resumes/ashish_resume.pdf"
  }
}
```

---

## ğŸš€ How to Trigger the Pipeline

### **Option 1: Automatic (Cron Job)**

```python
# Already configured in tasks/scheduler.py
# Runs every 15 minutes automatically

Schedule: Every 15 minutes
Function: check_new_resume_emails()
Action: Processes all connected users' Gmail accounts
```

**No action needed - it runs automatically when server starts!**

---

### **Option 2: Manual API Call**

```bash
# POST /api/v1/integrations/gmail/process-resumes
curl -X POST http://localhost:8000/api/v1/integrations/gmail/process-resumes \
  -H "Content-Type: application/json" \
  -d '{
    "user_id": "test_user_001",
    "use_mock": false
  }'

# Response:
{
  "status": "success",
  "user_id": "test_user_001",
  "candidates_found": 1,
  "candidates": [
    {
      "name": "Ashish Kumar",
      "email": "ashparmar08@gmail.com",
      ...
    }
  ]
}
```

---

### **Option 3: Frontend Button**

```javascript
// React example
async function processGmailResumes(userId) {
  const response = await fetch(
    'http://localhost:8000/api/v1/integrations/gmail/process-resumes',
    {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        user_id: userId,
        use_mock: false
      })
    }
  );
  
  const data = await response.json();
  console.log(`Found ${data.candidates_found} candidates!`);
}
```

---

## âœ… What's Working Now

### **Completed Features:**

1. âœ… **Gmail Connection** - Via Composio OAuth
2. âœ… **Email Fetching** - Last 7 days, with attachments
3. âœ… **File Download** - PDF, DOCX, TXT to local storage
4. âœ… **Data Extraction** - Name, email, phone, skills, experience, education
5. âœ… **AI Enrichment** - Google Gemini skill inference
6. âœ… **JSON Formatting** - Standard candidate structure
7. âœ… **Multi-user Support** - Different users, different accounts
8. âœ… **REST API** - 3 endpoints for frontend
9. âœ… **Cron Job** - Automatic processing every 15 min
10. âœ… **Error Handling** - Graceful fallbacks, logging

### **Tested with Real Data:**

```
Email: ashparmar08@gmail.com
File: Ashish_Kumar_team_IGNIITTE.pdf (70 KB)
âœ… Downloaded successfully
âœ… Extracted 17 skills
âœ… AI enriched 9 additional skills
âœ… Saved to data/candidates/ashparmar08_at_gmail_com.json
```

---

## ğŸ”œ Next Steps (Future Work)

### **Person 5: Scoring Pipeline**

```python
# TODO: Implement scoring
from modules.scoring.final_score import FinalScorer

scorer = FinalScorer()
score = scorer.score_candidate(
    candidate_json=candidate_data,
    jd_json=job_description
)

# Will add:
score = {
    'llm_score': 0.85,      # AI-based matching
    'keyword_score': 0.72,  # Keyword overlap
    'final_score': 0.79     # Combined score
}
```

### **Additional Features:**

- ğŸ“Š Candidate ranking dashboard
- ğŸ“§ Auto-reply to applicants
- ğŸ“… Interview scheduling integration
- ğŸ“‹ Export to Google Sheets
- ğŸ”” Email notifications for new candidates

---

## ğŸ“Š Pipeline Performance

```
Average Processing Time per Resume:
- Email Fetch: ~2 seconds
- File Download: ~1 second
- Extraction: ~3 seconds
- AI Enrichment: ~5 seconds (Gemini API call)
- Formatting: ~0.5 seconds
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total: ~12 seconds per resume

Batch Performance (10 resumes):
- Sequential: ~2 minutes
- Could be parallelized: ~30 seconds (future optimization)
```

---

## ğŸ§ª Testing

```bash
# Test complete pipeline
cd backend
python tests/test_gmail_integration.py

# Test with mock data (no Gmail needed)
python tests/test_mock_data.py

# Test API endpoints
uvicorn main:app --reload
python tests/test_api_endpoints.py
```

---

## ğŸ¯ Summary

**The Gmail pipeline is COMPLETE and WORKING!**

âœ… **Fully Automated:** Runs every 15 minutes  
âœ… **Multi-User:** Supports different Gmail accounts  
âœ… **AI-Powered:** Google Gemini enrichment  
âœ… **Production-Ready:** Error handling, logging, testing  
âœ… **Frontend-Ready:** REST API endpoints available  

**Next:** Person 5 implements scoring to rank candidates against job descriptions! ğŸš€
